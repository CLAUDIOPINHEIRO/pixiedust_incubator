{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cars 2015 - Twitter Data Analysis\n",
    "\n",
    "\n",
    "<br>\n",
    "Twitter tweets are an attractive data source to analyze as Twitter users tweet about many different topics in which they not only impart knowledge to others but also express their feelings and opinions. Analyzing this data can result in valuable insights and can be useful to detect trends and drive business decisions. Notebooks are a powerful platform for data scientists to analyze Twitter data.\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "This notebook shows how to analyze Twitter data to glean insights from the automotive industry. As the automotive industry is one of the largest industries in the world and still very much a growth industry, analyzing tweets about cars can assist manufacturers to pay closer attention to market dynamics and position their companies to take advantage of demographic  changes and shifts in consumer expectations.\n",
    "<br>\n",
    "\n",
    " The sample is structured into different sections. In the first sections, you will perform a general analysis on data set then you will go deeper in the analysis to gain meaningful insights about manufacturers.\n",
    "\n",
    "\n",
    "### Learning goals:\n",
    "1. Determine the countries with the highest number of tweets (based on the user profile information).\n",
    "\n",
    "2. Analyze tweet sentiments\n",
    "\n",
    "3. Draw insights from tweets about major car manufacturers world wide by combining Twitter timeline analysis with sentiment, determining gender distribution and location distribution.\n",
    "\n",
    "4. Draw insights about attractive car features across car makers.\n",
    "\n",
    "\n",
    "### Preparing the data set and data flow\n",
    "#### Data source\n",
    "The first step in the analysis process is to harvest the twitter data. In this sample, we use the DashDB connector to the IBM Insights for Twitter service to seamlessly specify a filter query and load the results into DashDB. A query is used to filter the tweets and return only those that were posted about 6 leading car manufacturers in 2015 such as Volkswagen, Toyota, Daimler, BMW and GM.\n",
    "\n",
    "##### Notes: \n",
    "1) The query captures alternative spellings of car manufactures. For example, Volkswagen and VW.\n",
    "\n",
    "2) The query does not filter out alternative meanings of a car model abbreviation. For example, GM can mean General Motors and Good Morning.\n",
    "\n",
    "3) The query is '(posted:2015-01-01,2015-12-31) (volkswagen OR vw OR toyota OR daimler OR mercedes OR bmw OR gm OR \"general motors\" OR tesla)'.\n",
    "\n",
    "4) The query above will produce around 5 Millions tweets which results in delays loading the data. User can limit the size of the data set by adding more filter constraints. e.g: **'posted:2015-01-01,2015-12-31 friends_count:5000 followers_count:5000 listed_count:5000 is:verified (sentiment:positive OR sentiment:negative OR sentiment:ambivalent) (volkswagen OR vw OR toyota OR daimler OR mercedes OR bmw OR gm OR \"general motors\" OR tesla)'**\n",
    "\n",
    "### Analyzing tweets\n",
    "\n",
    "In this notebook sample, you will use SparkContext which enables you to run tasks on the Spark cluster. Using Spark in notebooks enables you to analyze large amounts of data very efficiently. The sample begins with basic analysis steps which slowly progress into deeper analytic work. \n",
    "In this Notebook, we will analyze the loaded data to extract interesting insights and plots from it. This analysis is performed using SparkContext which enables us to run tasks on spark cluster. Using spark and notebooks is a very strong combination. It enables you to analyze big amount of data very efficiently. We will start with some basic analysis then go deeper gradually.\n",
    "\n",
    "\n",
    "##### Notebook structure\n",
    "1. Importing libraries\n",
    "2. Defining global variables and helper functions\n",
    "3. Acquiring the data\n",
    "4. Transforming the data\n",
    "5. Determining the distribution of tweets across geographies\n",
    "6. Analyzing tweet sentiments\n",
    "7. Analyzing Twitter timelines\n",
    "8. Drawing insights from tweets about car manufacturers\n",
    "9. Drawing insights about car features\n",
    "10. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Importing libraries\n",
    "Run the following cell to install the needed libraries you will work with in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install nltk --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import time\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import Javascript\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Defining global variables and helper functions\n",
    "\n",
    "In this sample, you will use the variables:\n",
    "- car_marker_list which contains all car manifacturers. Each element in the array is a list with all spelling variants of each manufacturer.\n",
    "- list car_makers_name_list which contains the most common spelling variant of each car manufacturer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_makers_list = [['bmw'], ['daimler', 'mercedes'], ['gm', 'general motors'], ['tesla'], ['toyota'], ['vw', 'volkswagen']]\n",
    "\n",
    "car_makers_name_list = []\n",
    "for car_maker in car_makers_list:\n",
    "    car_makers_name_list.append(car_maker[0].upper())\n",
    "\n",
    "#plotting variables\n",
    "ind = np.arange(len(car_makers_list)) #index list for plotting\n",
    "width = 0.8       # the width of the bars in the bar plots\n",
    "\n",
    "num_car_makers = len(car_makers_list)\n",
    "\n",
    "##car features #support English, Deutsch, french, Spanish\n",
    "electric_vehicle_terms = ['electric car', 'electric vehicle', 'electric motor', 'hybrid vehicle', 'Hybrid car', 'elektroauto', 'elektrofahrzeug', \n",
    "                          'hybridautos', 'voiture hyprid', 'coche híbrido', 'Auto Hibrido', 'vehículo híbrido', 'elektrovehikel', 'voiture électrique', 'coche eléctrico']\n",
    "auto_driver_terms = ['auto drive', 'autodrive', 'autonomous', 'driverless', 'self driving', 'robotic', 'autonomes', 'selbstfahrendes', 'autonome', 'autónomo']\n",
    "\n",
    "SCHEMA=\"DASH7504.\"\n",
    "PREFIX=\"PYCON_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample uses the helper function called GeoChart to plot the world map in a DOM element (an iframe).\n",
    "\n",
    "\n",
    "The helper function addMissingDates checks for any missing dates in DataFrames with time series data.\n",
    "* baseDataframe: this DataFrame contains all dates. It must have the column names [POSTING_TIME, NUM_TWEETS]\n",
    "* checkedDataframe: this DataFrame contains the dates that need to be checked. It must have the column names [POSTING_TIME, NUM_TWEETS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GeoChart(data_string, element):\n",
    "    return Javascript(\"\"\"\n",
    "        //container.show();\n",
    "        function draw() {\n",
    "          var chart = new google.visualization.GeoChart(document.getElementById(\"\"\" + element + \"\"\"));\n",
    "          chart.draw(google.visualization.arrayToDataTable(\"\"\" + data_string + \"\"\"));\n",
    "        }\n",
    "        google.load('visualization', '1.0', {'callback': draw, 'packages':['geochart']});\n",
    "        \"\"\", lib=\"https://www.google.com/jsapi\")\n",
    "\n",
    "def addMissingDates(baseDates, checkedDates):\n",
    "    temp = checkedDates.copy()\n",
    "    checkedDatesValues = checkedDates['POSTING_TIME']\n",
    "    for index, row in baseDates.iterrows():\n",
    "        if (not row['POSTING_TIME'] in checkedDatesValues.tolist()):\n",
    "            row['NUM_TWEETS'] = 0\n",
    "            temp = temp.append(row)\n",
    "    return temp.sort('POSTING_TIME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Acquiring data\n",
    "\n",
    "To access the data in dashDB, you must provide the dashDB service credentials. The data is retrieved from the database by using the Spark JDBC connector and is loaded into a Spark DataFrame in the notebook called df_CARS_TWEETS using sqlContext.read.jdbc. The dataframe has the same column names as the tweets table in dashDB.\n",
    "Run the next cell to use the credentials provided with this sample or adjust the credentials if you want to use your oun dashDB instance.\n",
    "\n",
    "#### Note: The data is only allowed to be used in the context of the current sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell reads the credentials and loads the data from dashBD into a DataFrame data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "props = {}\n",
    "props['user'] = 'dash7504'\n",
    "props['password'] = 'vtl2yZi1LX9n'\n",
    "\n",
    "jdbcurl='jdbc:db2://dashdb-entry-yp-dal09-07.services.dal.bluemix.net:50000/BLUDB'\n",
    "\n",
    "#get the data frame\n",
    "df_TWEETS = sqlContext.read.jdbc(jdbcurl, SCHEMA + PREFIX+'TWEETS', properties=props)\n",
    "df_TWEETS.printSchema()\n",
    "\n",
    "df_SENTIMENTS = sqlContext.read.jdbc(jdbcurl, SCHEMA + PREFIX + 'SENTIMENTS', properties=props)\n",
    "df_SENTIMENTS.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell counts the number of rows which were loaded into the DataFrame which is equivalent to the number of tweets available for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time print(\"Number of Tweets: \" + str(df_TWEETS.count()))\n",
    "%time print(\"Number of Sentiment Records: \" + str(df_SENTIMENTS.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import *\n",
    "udf = UserDefinedFunction(lambda x: 0 if x=='AMBIVALENT' else 1 if x=='POSITIVE' else -1, IntegerType())\n",
    "udf2 = UserDefinedFunction(lambda x: 'POSITIVE' if x>0 else 'NEGATIVE' if x<0 else 'AMBIVALENT', StringType())\n",
    "\n",
    "%time df=df_TWEETS.join(df_SENTIMENTS, \"MESSAGE_ID\")\n",
    "%time df=df.withColumn('SENTIMENT_POLARITY', udf(df.SENTIMENT_POLARITY) ).groupBy('MESSAGE_ID').agg(F.mean('SENTIMENT_POLARITY').alias(\"SENTIMENT_POLARITY\"))\n",
    "%time df=df.withColumn('SENTIMENT', udf2(df.SENTIMENT_POLARITY))\n",
    "%time df_JOIN_TWEETS=df_TWEETS.join(df, \"MESSAGE_ID\")\n",
    "%time df_JOIN_TWEETS.printSchema()\n",
    "%time df_JOIN_TWEETS.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Transforming the data\n",
    "\n",
    "\n",
    "You can't analyze the data that you have just loaded into the data frames the way it is. You must first mung the data.\n",
    "\n",
    "The output of the data transformation process is a new Spark DataFrame which has the target structure on which to base the data analysis. This Spark DataFrame called df_cleaned_tweets functions as the main data source for all further processing.\n",
    "\n",
    "Run the next cell to carry out the following transformations on the data:\n",
    "\n",
    "1) Remove the time from the timestamp values as only the date information is relevant.\n",
    "\n",
    "2) Change the values in the string columns like user country, state and city to upper case.\n",
    "\n",
    "3) Change the tweet posting location information from a string ('pos (42.000 42.000)') to a numeric value represented by the longitude and latitude coordinates. \n",
    "\n",
    "\n",
    "You will use the resulting dataframe (df_cleaned_tweets) as the base data source for all further step. The sample uses Spark to do all heavy computation. When it is time to plot or collect the results, the returned data is copied into the kernel memory, in other words moved from a Spark DataFrame to a pandas DataFrame.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getLongitudeLatitude(position):\n",
    "    parts = str(position).split('(')[1].split(')')[0].split(' ')\n",
    "    return parts\n",
    "\n",
    "def getLongitude(row):\n",
    "    if (row.MESSAGE_LOCATION is None):\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            parts = getLongitudeLatitude(row.MESSAGE_LOCATION)\n",
    "            lon = float(parts[0])\n",
    "            return lon\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def getLatitude(row):\n",
    "    if (row.MESSAGE_LOCATION is None):\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            parts = getLongitudeLatitude(row.MESSAGE_LOCATION)\n",
    "            lon = float(parts[1])\n",
    "            return lon\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def getDateIgnoreTime(row):\n",
    "    posting_time = parser.parse(str(row.MESSAGE_POSTED_TIME))\n",
    "    posting_time = posting_time.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    return posting_time\n",
    "\n",
    "#Mung Data\n",
    "schema=StructType([\n",
    "        StructField('MESSAGE_ID',StringType()),\n",
    "        StructField('POSTING_TIME',TimestampType()),\n",
    "        StructField('MESSAGE_BODY',StringType()),\n",
    "        StructField('USER_GENDER',StringType()),\n",
    "        StructField('USER_STATE',StringType()),\n",
    "        StructField('USER_COUNTRY',StringType()),\n",
    "        StructField('USER_CITY',StringType()),\n",
    "        StructField('MESSAGE_LANGUAGE',StringType()),\n",
    "        StructField('MESSAGE_LOCATION_LONGITUDE',FloatType()),\n",
    "        StructField('MESSAGE_LOCATION_LATITUDE',FloatType()),\n",
    "        StructField('SENTIMENT',StringType()),\n",
    "        StructField('USER_FOLLOWERS_COUNT',IntegerType()),\n",
    "        StructField('USER_FRIENDS_COUNT',IntegerType())\n",
    "    ])\n",
    "df_cleaned_tweets = sqlContext.createDataFrame(df_JOIN_TWEETS.map(lambda row: [row.MESSAGE_ID,\n",
    "                        getDateIgnoreTime(row),\n",
    "                        row.MESSAGE_BODY,\n",
    "                        row.USER_GENDER,\n",
    "                        unicode(row.USER_STATE).upper(),\n",
    "                        unicode(row.USER_COUNTRY).upper(),\n",
    "                        unicode(row.USER_CITY).upper(),\n",
    "                        row.MESSAGE_LANGUAGE,\n",
    "                        getLongitude(row),\n",
    "                        getLatitude(row),\n",
    "                        row.SENTIMENT,\n",
    "                        row.USER_FOLLOWERS_COUNT,\n",
    "                        row.USER_FRIENDS_COUNT\n",
    "                    ]), schema)\n",
    "\n",
    "df_cleaned_tweets.registerTempTable('CARS2015_TWEETS_CLEANED')\n",
    "df_cleaned_tweets.cache()\n",
    "df_cleaned_tweets.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Determining the distribution of tweets across geographies\n",
    "\n",
    "This section shows you how to extract the countries, which have the highest number of tweets. To do that the data is grouped according to the USER_COUNTRY column and the rows in each group are counted. Then the groups are sorted in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#group by country\n",
    "df_cleaned_tweets_countries = df_cleaned_tweets.groupBy('USER_COUNTRY')\\\n",
    "                                .agg(F.count('MESSAGE_BODY').alias('NUM_TWEETS'))\\\n",
    "                                .orderBy('NUM_TWEETS', ascending=False)\n",
    "\n",
    "df_cleaned_tweets_countries.cache()\n",
    "df_cleaned_tweets_countries.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_df_cleaned_tweets_countries = df_cleaned_tweets_countries.toPandas()\n",
    "p_df_cleaned_tweets_countries.ix[p_df_cleaned_tweets_countries['USER_COUNTRY'] == 'NONE', 'USER_COUNTRY'] = 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cells show you two ways of plotting the countries with the largest number of tweets. As this data needs no further munging, the data is copied into a pandas DataFrame which is used for plotting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_plotted_countries = 10\n",
    "\n",
    "countries = p_df_cleaned_tweets_countries['USER_COUNTRY'][:num_plotted_countries]\n",
    "num_tweets = p_df_cleaned_tweets_countries['NUM_TWEETS'][:num_plotted_countries]\n",
    "y_pos = np.arange(len(countries))\n",
    "colors = np.repeat('b', num_plotted_countries - 1).tolist()\n",
    "colors = ['gray'] + colors\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.barh(y_pos, num_tweets, align='center', color=colors)\n",
    "plt.yticks(y_pos, countries)\n",
    "plt.xlabel('Number of Tweets')\n",
    "plt.title('Tweets Country Distribution based on the User Profile')\n",
    "plt.ylim(-1, len(y_pos))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%html\n",
    "<div id=\"plot_div\" style=\"width: 900px; height: 500px;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countries = p_df_cleaned_tweets_countries['USER_COUNTRY']\n",
    "num_tweets = p_df_cleaned_tweets_countries['NUM_TWEETS']\n",
    "\n",
    "data = \"[['Country', 'Num Tweets']\"\n",
    "index = 0\n",
    "for country in countries:\n",
    "    country = country.replace(\"'\", \"\")\n",
    "    data = data + \", ['\" + country + \"', \" + str(num_tweets[index]) + \"]\"\n",
    "    index += 1\n",
    "data = data + \"]\"\n",
    "\n",
    "GeoChart(data, \"'plot_div'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you won't need the data frames related to countries any longer run the following cell to clear the memory of those variables (both Spark and pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cleaned_tweets_countries.unpersist()\n",
    "df_cleaned_tweets_countries = None\n",
    "p_df_cleaned_tweets_countries = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Analyzing tweet sentiments\n",
    "\n",
    "Sentiment analysis is one of the most valuable sources of information that the IBM twitter API provides. By giving each tweet a sentiment value, you can determine whether the content of a tweet is positive, negative, ambivalent, neutral, or NULL, if no value is provided by the API. Unfortunately, a sentiment value is provided for English, German, French, and Spanish tweets only. As the data set also has tweets in other languages, only a sub set of the tweets in the data set have a sentiment value.\n",
    "\n",
    "The cells in the following section show you how to plot the sentiment values of all tweets in the data set. This is done by grouping tweets according to their sentiment value and then counting the number of tweets in each group.\n",
    "\n",
    "After you have plotted the results, run the cell to release the memory of the variables you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get number of tweets with P N U sentiment by grouping the sentiment value\n",
    "tweets_grouped_by_sentiment = df_cleaned_tweets\\\n",
    "                .groupBy('SENTIMENT')\\\n",
    "                .agg(F.count('MESSAGE_ID').alias('NUM_TWEETS'))\n",
    "\n",
    "tweets_grouped_by_sentiment.cache()\n",
    "tweets_grouped_by_sentiment.show(5)\n",
    "\n",
    "#move the results to pandas\n",
    "p_tweets_grouped_by_sentiment = tweets_grouped_by_sentiment.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data plot 1\n",
    "plot1_labels = p_tweets_grouped_by_sentiment['SENTIMENT']\n",
    "plot1_values = p_tweets_grouped_by_sentiment['NUM_TWEETS']\n",
    "plot1_colors = ['blue', 'red', 'gray', 'yellow', 'green']\n",
    "\n",
    "#data plot 2\n",
    "cond1 = (p_tweets_grouped_by_sentiment['SENTIMENT'] == 'POSITIVE')\n",
    "cond2 = (p_tweets_grouped_by_sentiment['SENTIMENT'] == 'NEGATIVE')\n",
    "\n",
    "pMessage_sentiment_statistics_defined = p_tweets_grouped_by_sentiment[cond1 | cond2]\n",
    "plot2_labels = pMessage_sentiment_statistics_defined['SENTIMENT']\n",
    "plot2_values = pMessage_sentiment_statistics_defined['NUM_TWEETS']\n",
    "plot2_colors = ['blue', 'red']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(23, 10))\n",
    "\n",
    "axes[0].pie(plot1_values,  labels=plot1_labels, colors=plot1_colors, autopct='%1.1f%%')\n",
    "axes[0].set_title('Percentage of Sentiment Values in all Tweets')\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].legend(loc=\"upper right\", labels=plot1_labels)\n",
    "\n",
    "# Plot\n",
    "axes[1].pie(plot2_values,  labels=plot2_labels, colors=plot2_colors, autopct='%1.1f%%')\n",
    "axes[1].set_title('Percentage of Positive and Negative Sentiment Values in all Tweets')\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].legend(loc=\"upper right\", labels=plot2_labels)\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_grouped_by_sentiment.unpersist()\n",
    "tweets_grouped_by_sentiment = None\n",
    "p_tweets_grouped_by_sentiment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Analyzing Twitter timelines\n",
    "\n",
    "To learn more about which car manufacturing events occurred in 2015, you can plot data over time. The code cells in the following section group all tweets created in 2015 by their posting date (and the sentiment value) and counts the number of tweets per date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#group by year-month-day and the sentiment\n",
    "df_num_tweets_and_sentiment_over_time = df_cleaned_tweets.groupBy('POSTING_TIME', 'SENTIMENT')\\\n",
    "                    .agg(F.count('MESSAGE_BODY').alias('NUM_TWEETS'))\\\n",
    "                    .orderBy('POSTING_TIME', ascending=True)\n",
    "\n",
    "#group by year-month-day\n",
    "df_num_tweets_over_time = df_num_tweets_and_sentiment_over_time.groupBy('POSTING_TIME')\\\n",
    "                    .agg(F.sum('NUM_TWEETS').alias('NUM_TWEETS'))\\\n",
    "                    .orderBy('POSTING_TIME', ascending=True)\n",
    "\n",
    "#move to Pandas\n",
    "p_df_num_tweets_and_sentiment_over_time = df_num_tweets_and_sentiment_over_time.toPandas()\n",
    "p_df_num_tweets_over_time = df_num_tweets_over_time.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to prepare the data for plotting by moving data with different sentiment values into different data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_mask = p_df_num_tweets_and_sentiment_over_time['SENTIMENT'] == 'POSITIVE'\n",
    "negative_mask = p_df_num_tweets_and_sentiment_over_time['SENTIMENT'] == 'NEGATIVE'\n",
    "neutral_mask = p_df_num_tweets_and_sentiment_over_time['SENTIMENT'] == 'NEUTRAL'\n",
    "ambivalent_mask = p_df_num_tweets_and_sentiment_over_time['SENTIMENT'] == 'AMBIVALENT'\n",
    "null_mask = p_df_num_tweets_and_sentiment_over_time['SENTIMENT'].isnull()\n",
    "\n",
    "p_df_num_tweets_and_sentiment_over_time_positive = p_df_num_tweets_and_sentiment_over_time[positive_mask]\n",
    "p_df_num_tweets_and_sentiment_over_time_negative = p_df_num_tweets_and_sentiment_over_time[negative_mask]\n",
    "p_df_num_tweets_and_sentiment_over_time_neutral = p_df_num_tweets_and_sentiment_over_time[neutral_mask]\n",
    "p_df_num_tweets_and_sentiment_over_time_ambivalent = p_df_num_tweets_and_sentiment_over_time[ambivalent_mask]\n",
    "p_df_num_tweets_and_sentiment_over_time_null = p_df_num_tweets_and_sentiment_over_time[null_mask]\n",
    "\n",
    "p_df_num_tweets_and_sentiment_over_time_positive = addMissingDates(p_df_num_tweets_over_time, p_df_num_tweets_and_sentiment_over_time_positive)\n",
    "p_df_num_tweets_and_sentiment_over_time_negative = addMissingDates(p_df_num_tweets_over_time, p_df_num_tweets_and_sentiment_over_time_negative)\n",
    "p_df_num_tweets_and_sentiment_over_time_neutral = addMissingDates(p_df_num_tweets_over_time, p_df_num_tweets_and_sentiment_over_time_neutral)\n",
    "p_df_num_tweets_and_sentiment_over_time_ambivalent = addMissingDates(p_df_num_tweets_over_time, p_df_num_tweets_and_sentiment_over_time_ambivalent)\n",
    "p_df_num_tweets_and_sentiment_over_time_null = addMissingDates(p_df_num_tweets_over_time, p_df_num_tweets_and_sentiment_over_time_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to plot your results after data munging. First plot the number of tweets about Volkswagen, Toyota, BMW, Daimler, and General Motors spread across 2015, then plot their positive and negative sentiment values, and lastly plot only the sentiment value applied to the number of tweets.\n",
    "\n",
    "After you've completed plotting the results, clear the memory of the variables you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#take the beginning of each month\n",
    "mask_1day = p_df_num_tweets_over_time['POSTING_TIME'].map(lambda x: x.day) == 1\n",
    "x = p_df_num_tweets_over_time[mask_1day]['POSTING_TIME']\n",
    "y = p_df_num_tweets_over_time['NUM_TWEETS']\n",
    "\n",
    "#positive preparation\n",
    "py = p_df_num_tweets_and_sentiment_over_time_positive['NUM_TWEETS']\n",
    "#negative preparation\n",
    "ny = p_df_num_tweets_and_sentiment_over_time_negative['NUM_TWEETS']\n",
    "#undefined preparation\n",
    "ney = p_df_num_tweets_and_sentiment_over_time_neutral['NUM_TWEETS']\n",
    "#ambivalent preparation\n",
    "ay = p_df_num_tweets_and_sentiment_over_time_ambivalent['NUM_TWEETS']\n",
    "#null preparation - undefined\n",
    "nully = p_df_num_tweets_and_sentiment_over_time_null['NUM_TWEETS']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(20, 10))\n",
    "\n",
    "#plot1\n",
    "axes[0].plot(range(len(y)), y, linewidth=2)\n",
    "axes[0].set_xticks(x.index.tolist())\n",
    "axes[0].set_xticklabels([date.strftime(\"%Y-%m-%d\") for date in x])\n",
    "axes[0].margins = 0\n",
    "axes[0].set_xlabel('Date/Time')\n",
    "axes[0].set_ylabel('Num of Tweets')\n",
    "axes[0].set_title('Number of Tweets Over Time - ALL TWEETS')\n",
    "axes[0].set_xlim(0, len(y))\n",
    "axes[0].legend(loc=\"upper right\", labels=['All Tweets'])\n",
    "#axes[0].axhline(y=12700, c=\"red\")\n",
    "\n",
    "axes[1].plot(range(len(y)), y, linewidth=2, color='blue')\n",
    "axes[1].plot(range(len(py)), py, linewidth=2, color='green')\n",
    "axes[1].plot(range(len(ny)), ny, linewidth=2, color='red')\n",
    "\n",
    "axes[1].set_xticks(x.index.tolist())\n",
    "axes[1].set_xticklabels([date.strftime(\"%Y-%m-%d\") for date in x])\n",
    "axes[1].margins = 0\n",
    "axes[1].set_xlabel('Date/Time')\n",
    "axes[1].set_ylabel('Num of Tweets')\n",
    "axes[1].set_title('Number of Tweets Over Time - All, Positive and Negative')\n",
    "axes[1].set_xlim(0, len(y))\n",
    "axes[1].legend(loc=\"upper right\", labels=['All Tweets', 'Positive', 'Negative', 'Undefined Sentiment'])\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_num_tweets_and_sentiment_over_time.unpersist()\n",
    "df_num_tweets_over_time.unpersist()\n",
    "\n",
    "df_num_tweets_and_sentiment_over_time = None\n",
    "df_num_tweets_over_time = None\n",
    "\n",
    "p_df_num_tweets_and_sentiment_over_time = None\n",
    "#we will need the variable p_df_num_tweets_over_time\n",
    "\n",
    "p_df_num_tweets_and_sentiment_over_time_positive = None\n",
    "p_df_num_tweets_and_sentiment_over_time_negative = None\n",
    "p_df_num_tweets_and_sentiment_over_time_neutral = None\n",
    "p_df_num_tweets_and_sentiment_over_time_ambivalent = None\n",
    "p_df_num_tweets_and_sentiment_over_time_null = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Drawing insights from tweets about car manufacturers\n",
    "\n",
    "This section combines different types of analyses to dig deeper into the list of car manufacturers (Volkswagen, Toyota, BMW, Daimler, and  General Motors). The purpse of the analyses is to obtain car manufacturer-based insights from tweets that could be interesting and useful to detect potential car buyers. \n",
    "\n",
    "The first step is to detect the tweets that mention certain car manufacturers. Run the next cell to munge the data into a new data frame that has additional columns for each car manufacturer. The value in this column in each row indicates whether the car company was mentioned in a tweet or not. \n",
    "\n",
    "This new data frame is the new data source for subsequent computations in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hasWord(message, word):\n",
    "    return (word in message)\n",
    "\n",
    "def checkCarMaker(message):\n",
    "    tmp = []\n",
    "    for car_maker_list_var in car_makers_list:\n",
    "        contain = False\n",
    "        for car_maker in car_maker_list_var:\n",
    "            if (hasWord(message, car_maker)):\n",
    "                contain = True\n",
    "        tmp.extend([contain])\n",
    "    return tmp\n",
    "\n",
    "def checkCarFeatures(message, feature_list):\n",
    "    tmp = []    \n",
    "    contain = False\n",
    "    for term in feature_list:\n",
    "        if (hasWord(message, term.decode('utf8'))):\n",
    "            contain = True\n",
    "    tmp.extend([contain])\n",
    "    return tmp\n",
    "\n",
    "def getInfluence(tweet):\n",
    "    return ((tweet.USER_FOLLOWERS_COUNT + tweet.USER_FRIENDS_COUNT) / 2)\n",
    "\n",
    "def getAllAttributes(tweet):\n",
    "    message = unicode(tweet.MESSAGE_BODY).lower()\n",
    "    \n",
    "    #message id and line\n",
    "    tmp = [tweet.MESSAGE_ID, tweet.MESSAGE_BODY, tweet.SENTIMENT, tweet.USER_GENDER, unicode(tweet.USER_COUNTRY).upper()\\\n",
    "               , tweet.POSTING_TIME, getInfluence(tweet)]\n",
    "\n",
    "    #competitors in line\n",
    "    tmp.extend(checkCarMaker(message))\n",
    "    \n",
    "    #electric cars - autodrive cars\n",
    "    tmp.extend(checkCarFeatures(message, electric_vehicle_terms))\n",
    "    tmp.extend(checkCarFeatures(message, auto_driver_terms))\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "columns_names = ['MESSAGE_ID', 'MESSAGE_BODY', 'SENTIMENT', 'USER_GENDER', 'USER_COUNTRY', 'POSTING_TIME', 'INFLUENCE']\n",
    "for carMakerName in car_makers_name_list:\n",
    "        columns_names.append(carMakerName)\n",
    "columns_names.append('ELECTRIC_CARS')\n",
    "columns_names.append('AUTO_DRIVE')\n",
    "\n",
    "df_tweets_car_maker = sqlContext.createDataFrame(df_cleaned_tweets\n",
    "                             .map(lambda x: getAllAttributes(x)), columns_names)\n",
    "\n",
    "df_tweets_car_maker.cache()\n",
    "df_tweets_car_maker.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analyzing Twitter timelines\n",
    "\n",
    "\n",
    "You will plot the data over time according to each car manufacturer. This can be done by using the Spark data frame that you just constructed. You will filter the data by each car maker and then regroup the resulting data frame according to the posting time of the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Calculating the number of tweets over 2015 for each car maker:'\n",
    "\n",
    "car_maker_results_list = []\n",
    "for car_maker in car_makers_name_list:\n",
    "    #get competitor dataframe\n",
    "    df_car_maker = df_tweets_car_maker.filter(df_tweets_car_maker[car_maker] == True)\n",
    "    overall_car_maker_time_data = df_car_maker.groupBy('POSTING_TIME')\\\n",
    "                        .agg(F.count('MESSAGE_ID').alias('COUNT'))\\\n",
    "                        .orderBy('POSTING_TIME' , ascending=True)\n",
    "\n",
    "    p_overall_car_maker_time_data = overall_car_maker_time_data.toPandas()\n",
    "    car_maker_results_list.append(p_overall_car_maker_time_data)\n",
    "    \n",
    "    overall_car_maker_time_data.unpersist()\n",
    "    print 'Done for ' + car_maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the distribution of tweets about Volkswagen, Toyota, BMW, Daimler, and  General Motors in 2015 based on the tweet posting dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask_1day = p_df_num_tweets_over_time['POSTING_TIME'].map(lambda x: x.day) == 1\n",
    "x = p_df_num_tweets_over_time[mask_1day]['POSTING_TIME']\n",
    "\n",
    "#plotting\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 4))\n",
    "colors = ['blue', 'red', 'green', 'yellow', 'pink', 'black']\n",
    "\n",
    "for i in range(0, len(car_makers_name_list)):\n",
    "    y = car_maker_results_list[i]['COUNT']\n",
    "    axes.plot(range(len(y)), y, linewidth=2, color=colors[i])\n",
    "\n",
    "axes.set_xticks(x.index.tolist())\n",
    "axes.set_xticklabels([date.strftime(\"%Y-%m-%d\") for date in x])\n",
    "axes.margins = 0\n",
    "axes.set_xlabel('Date/Time')\n",
    "axes.set_ylabel('Num of Tweets')\n",
    "axes.set_title('Number of Tweets Over Time according to a Car Manufacturer- ALL TWEETS')\n",
    "axes.set_xlim(0, len(car_maker_results_list[0]))\n",
    "axes.legend(loc=\"upper right\", labels=car_makers_name_list)\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover insight explaining the peak of tweets for VW between September 15 and October 15 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tweets_debacle = df_tweets_car_maker.filter((df_tweets_car_maker[\"VW\"] == True) &\\\n",
    "                   (df_tweets_car_maker.POSTING_TIME > '2015-09-15 0.0.0') & \\\n",
    "                   (df_tweets_car_maker.POSTING_TIME < '2015-10-15 0.0.0'))\n",
    "df_tweets_debacle.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "cachedStopWords.extend([\"Volkswagen\",\"VW\",\"de\",\"el\",\"que\",\"en\"])\n",
    "\n",
    "tagsRDD = df_tweets_debacle.flatMap( lambda t: re.split(\"\\s\", t.MESSAGE_BODY))\\\n",
    "    .filter( lambda word: not word.startswith(\"http\") and all(ord(c) < 128 for c in word) and word not in cachedStopWords and len(word)>3)\\\n",
    "    .map( lambda word : (word, 1 ))\\\n",
    "    .reduceByKey(add, 10).map(lambda (a,b): (b,a)).sortByKey(False).map(lambda (a,b):(b,a))\n",
    "top10tags = tagsRDD.take(10)\n",
    "\n",
    "params = plt.gcf()\n",
    "plSize = params.get_size_inches()\n",
    "params.set_size_inches( (plSize[0]*2, plSize[1]*2) )\n",
    "\n",
    "labels = [i[0] for i in top10tags]\n",
    "sizes = [int(i[1]) for i in top10tags]\n",
    "colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral', \"beige\", \"paleturquoise\", \"pink\", \"lightyellow\", \"coral\"]\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors,autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "car_maker_results_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding sentiment analysis\n",
    "\n",
    "Next extend your analysis and plot results that combine posting time and sentiment change in tweets in 2015. \n",
    "Any positive or negative peaks correspond to events that occurred in the car company at a certain time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Calculating the number of positive and negative tweets over 2015 for each car maker:'\n",
    "\n",
    "car_maker_results_list = []\n",
    "for car_maker in car_makers_name_list:\n",
    "    #get competitor dataframe\n",
    "    df_car_maker = df_tweets_car_maker.filter(df_tweets_car_maker[car_maker] == True)\n",
    "    \n",
    "    time_sentiment_car_maker_data = df_car_maker.groupBy('POSTING_TIME', 'SENTIMENT')\\\n",
    "                                        .agg(F.count('MESSAGE_ID').alias('COUNT'))\\\n",
    "                                        .orderBy('POSTING_TIME', ascending=True)\n",
    "    \n",
    "    time_sentiment_car_maker_data.cache()\n",
    "    \n",
    "    time_positive_sentiment_car_maker_data = time_sentiment_car_maker_data.filter(time_sentiment_car_maker_data['SENTIMENT'] == 'POSITIVE')\n",
    "    time_negative_sentiment_car_maker_data = time_sentiment_car_maker_data.filter(time_sentiment_car_maker_data['SENTIMENT'] == 'NEGATIVE')\n",
    "\n",
    "    p_time_positive_sentiment_car_maker_data = time_positive_sentiment_car_maker_data.toPandas()\n",
    "    p_time_negative_sentiment_car_maker_data = time_negative_sentiment_car_maker_data.toPandas()\n",
    "    \n",
    "    #collect results\n",
    "    car_maker_results_list.append([p_time_positive_sentiment_car_maker_data, p_time_negative_sentiment_car_maker_data])\n",
    "    time_sentiment_car_maker_data.unpersist()\n",
    "    print 'Done for ' + car_maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask_1day = p_df_num_tweets_over_time['POSTING_TIME'].map(lambda x: x.day) == 1\n",
    "x = p_df_num_tweets_over_time[mask_1day]['POSTING_TIME']\n",
    "\n",
    "for i in range(0, len(car_makers_name_list)):\n",
    "    car_maker_results_list[i][0] = addMissingDates(p_df_num_tweets_over_time, car_maker_results_list[i][0])\n",
    "    car_maker_results_list[i][1] = addMissingDates(p_df_num_tweets_over_time, car_maker_results_list[i][1])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(car_maker_results_list), ncols=1, figsize=(20, 15))\n",
    "colors = ['blue', 'red', 'green', 'yellow', 'black']\n",
    "\n",
    "for i in range(0, len(car_makers_name_list)):\n",
    "    y1 = car_maker_results_list[i][0]['COUNT']\n",
    "    y2 = car_maker_results_list[i][1]['COUNT']\n",
    "    \n",
    "    axes[i].plot(range(len(y1)), y1, linewidth=2, color='green')\n",
    "    axes[i].plot(range(len(y2)), y2, linewidth=1, color='red')\n",
    "    axes[i].set_xticks(x.index.tolist())\n",
    "    axes[i].set_xticklabels([date.strftime(\"%Y-%m-%d\") for date in x])\n",
    "    axes[i].margins = 0\n",
    "    axes[i].set_xlabel('Date/Time')\n",
    "    axes[i].set_ylabel('Num of Tweets')\n",
    "    axes[i].set_title('Number of Tweets about ' + car_makers_name_list[i] + ' Over Time - Positive and Negative')\n",
    "    axes[i].set_xlim(0, len(car_maker_results_list[0][0]))\n",
    "    axes[i].legend(loc=\"upper right\", labels=['Positive', 'Negative'])\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculating the number of tweets across car manufacturers\n",
    "\n",
    "The next code cells calculate the number of tweets about certain car manufacturers and then plot the resulting numbers in a bar chart and as percentages in a pie chart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Calculating the number of tweets that mention one of the car makers:'\n",
    "\n",
    "car_maker_tweets_count = []\n",
    "for car_maker in car_makers_name_list:\n",
    "    df_car_maker = df_tweets_car_maker.filter(df_tweets_car_maker[car_maker] == True)\n",
    "    car_maker_tweets_count.append(df_car_maker.count())\n",
    "    print 'Done for ' + car_maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(23, 8))\n",
    "\n",
    "axes[0].bar(ind, car_maker_tweets_count, width, color='b', align='center')\n",
    "axes[0].set_ylabel('Num Tweets')\n",
    "axes[0].set_title('Number of tweets that mention a certain Car Manufacturer')\n",
    "axes[0].set_xticks(ind)\n",
    "axes[0].set_xticklabels(car_makers_name_list)\n",
    "\n",
    "# Plot\n",
    "axes[1].pie(car_maker_tweets_count,autopct='%1.1f%%', labels=car_makers_name_list)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_title('Percentage of tweets that mention a certain Car Manufacturer')\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the distribution of positive and negative tweets\n",
    "\n",
    "To determine the distribution of sentiment values of the tweets for each car manufacturers, run the next cell to calculate the number of positive and negative tweets across car makers and plot the results next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_sum_car_makers = []\n",
    "negative_sum_car_makers = []\n",
    "\n",
    "for i in range(0, len(car_makers_name_list)):\n",
    "    car_maker = car_makers_name_list[i]\n",
    "    car_maker_results_list[i][0] = car_maker_results_list[i][0].fillna(0)\n",
    "    car_maker_results_list[i][1] = car_maker_results_list[i][1].fillna(0)\n",
    "    positive_sum_car_makers.extend([car_maker_results_list[i][0]['COUNT'].sum()])\n",
    "    negative_sum_car_makers.extend([car_maker_results_list[i][1]['COUNT'].sum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_value_P_N = np.add(positive_sum_car_makers, negative_sum_car_makers)\n",
    "competitors_list_rest = np.subtract(car_maker_tweets_count, sum_value_P_N)\n",
    "\n",
    "#plot\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(23, 8))\n",
    "\n",
    "#axes[0].bar(ind, competitors_list, width, color='b', align='center')\n",
    "axes[0].bar(ind, positive_sum_car_makers, width, color='b', align='center')\n",
    "axes[0].bar(ind, negative_sum_car_makers, width, color='r', bottom=positive_sum_car_makers, align='center')\n",
    "axes[0].bar(ind, competitors_list_rest, width, color='gray', align='center',bottom=sum_value_P_N)\n",
    "axes[0].set_ylabel('Num Tweets')\n",
    "axes[0].set_title('Number of tweets that mention a certain Car Manufacturer')\n",
    "axes[0].set_xticks(ind)\n",
    "axes[0].set_xticklabels(car_makers_name_list)\n",
    "axes[0].legend(loc=\"upper left\", labels=['POSITIVE', 'NEGATIVE', 'Others'])\n",
    "\n",
    "axes[1].bar(ind, positive_sum_car_makers, width, color='b', align='center')\n",
    "axes[1].bar(ind, negative_sum_car_makers, width, color='r', bottom=positive_sum_car_makers, align='center')\n",
    "axes[1].set_ylabel('Num Tweets')\n",
    "axes[1].set_title('Positive / Negative tweets - Car Manufacturer')\n",
    "axes[1].set_xticks(ind)\n",
    "axes[1].set_xticklabels(car_makers_name_list)\n",
    "axes[1].legend(loc=\"upper left\", labels=['POSITIVE', 'NEGATIVE'])\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show that in general there are more positive than negative tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining gender distribution \n",
    "\n",
    "Another interesting insight when analyzing tweets about certain car manufacturers and what car manufacturers might want to pay more attention to for marketing purposes is the distribution of tweets between male and female users. \n",
    "\n",
    "The following cells calculate the gender distribution across each competitor and plot the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Calculating the distribution of male and female in tweets over 2015 for each competitors:'\n",
    "\n",
    "car_maker_info_list_M_F = []\n",
    "\n",
    "for car_maker in car_makers_name_list:\n",
    "    df_car_maker = df_tweets_car_maker.filter(df_tweets_car_maker[car_maker] == True)\n",
    "    car_maker_gender_data = df_car_maker.groupBy('USER_GENDER')\\\n",
    "                                .agg(F.count('MESSAGE_ID').alias('COUNT'))\n",
    "    car_maker_gender_data.cache()\n",
    "\n",
    "    p_car_maker_gender_data_male = car_maker_gender_data.filter(car_maker_gender_data['USER_GENDER'] == 'male').toPandas()\n",
    "    p_car_maker_gender_data_female = car_maker_gender_data.filter(car_maker_gender_data['USER_GENDER'] == 'female').toPandas()\n",
    "    car_maker_info_list_M_F.append([p_car_maker_gender_data_male, p_car_maker_gender_data_female])    \n",
    "    car_maker_gender_data.unpersist()\n",
    "    print 'Done for ' + car_maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare data for plotting\n",
    "car_maker_list_female = []\n",
    "car_maker_list_male = []\n",
    "for i in range(0, len(car_maker_info_list_M_F)):\n",
    "    car_maker_list_female.append(0 if car_maker_info_list_M_F[i][1]['COUNT'].empty else car_maker_info_list_M_F[i][1]['COUNT'][0])\n",
    "    car_maker_list_male.append(0 if car_maker_info_list_M_F[i][0]['COUNT'].empty else car_maker_info_list_M_F[i][0]['COUNT'][0])\n",
    "\n",
    "sum_value_M_F = np.add(car_maker_list_male, car_maker_list_female)\n",
    "car_maker_list_M_F_rest = np.subtract(car_maker_tweets_count, sum_value_M_F)\n",
    "\n",
    "#plotting\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(23, 8))\n",
    "\n",
    "axes[0].bar(ind, car_maker_list_male, width, color='g', align='center')\n",
    "axes[0].bar(ind, car_maker_list_female, width, color='b',bottom=car_maker_list_male, align='center')\n",
    "axes[0].bar(ind, car_maker_list_M_F_rest, width, color='gray', align='center',bottom=sum_value_M_F)\n",
    "axes[0].set_ylabel('Num Tweets')\n",
    "axes[0].set_title('Number of tweets that mention a certain Competitor')\n",
    "axes[0].set_xticks(ind)\n",
    "axes[0].set_xticklabels(car_makers_name_list)\n",
    "axes[0].legend(loc=\"upper left\", labels=['MALE', 'FEMALE', 'UNKNOWN'])\n",
    "\n",
    "axes[1].bar(ind, car_maker_list_male, width, color='g', align='center')\n",
    "axes[1].bar(ind, car_maker_list_female, width, color='b',bottom=car_maker_list_male, align='center')\n",
    "axes[1].set_ylabel('Num Tweets')\n",
    "axes[1].set_title('Male / Female Distribution - Competitors')\n",
    "axes[1].set_xticks(ind)\n",
    "axes[1].set_xticklabels(car_makers_name_list)\n",
    "axes[1].legend(loc=\"upper left\", labels=['MALE', 'FEMALE'])\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen in the plotted results that in general, men post more tweets about cars than women do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring influence\n",
    "\n",
    "In this section, we will calculate the average value of the influence variable of the people who tweeted about a certain car maker. The influence varable is calculated by: \n",
    "\n",
    "$$Influence = ( \\space num \\space of \\space followers + \\space number \\space of \\space friends \\space ) \\div 2$$\n",
    "\n",
    "\n",
    "The influence score gives an indication whether someone is a famous person or a public figure in society or whether the twitter account is owned by the media or a company. This average value gives an indication about the people who are interested in a certain car maker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns a list of pandas DFs.\n",
    "def getInsights_Influence(sparkDF,car_maker_list):\n",
    "    print 'Calculating the influence insight of the users in tweets over 2015 for each competitors:'\n",
    "\n",
    "    car_maker_result_list = []\n",
    "    for car_maker in car_maker_list:\n",
    "        df_car_maker = sparkDF.filter(sparkDF[car_maker] == True)\n",
    "        car_maker_insight_data = df_car_maker.select(F.avg('INFLUENCE').alias('AVE_INFLUENCE'))\n",
    "        car_maker_result_list.append(car_maker_insight_data.toPandas())\n",
    "        df_car_maker.unpersist()\n",
    "        car_maker_insight_data.unpersist()\n",
    "        print 'Done for ' + car_maker\n",
    "    return car_maker_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influenceInsights = getInsights_Influence(df_tweets_car_maker, car_makers_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influence_list = []\n",
    "for i in range(0, len(car_makers_name_list)):\n",
    "    influence_list.append(influenceInsights[i]['AVE_INFLUENCE'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 8))\n",
    "\n",
    "rects = axes.bar(ind, influence_list, width, color='b', align='center')\n",
    "axes.set_ylabel('Average Value of the Influence Score')\n",
    "\n",
    "#influence=(number of friends + number of followers)/2\n",
    "axes.set_title('The Average of the User Influence for Each Car Maker')\n",
    "axes.set_xticks(ind)\n",
    "axes.set_xticklabels(car_makers_name_list)\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "influenceInsights = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the distribution of tweets by country across car manufacturer\n",
    "\n",
    "The next cells calculate in which countries the most tweets were posted about car manufacturers. This information can support marketing and sales when evaluating potential customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Calculating the country distribution of tweets over 2015 for each car maker:'\n",
    "\n",
    "car_maker_info_list_countries = []\n",
    "i = 0\n",
    "\n",
    "for car_maker in car_makers_name_list:\n",
    "    df_car_maker = df_tweets_car_maker.filter(df_tweets_car_maker[car_maker] == True)\n",
    "    car_maker_country_data = df_car_maker.groupBy('USER_COUNTRY')\\\n",
    "                                .agg(F.count('MESSAGE_ID').alias('COUNT'))\\\n",
    "                                .orderBy('COUNT', ascending=False)\n",
    "    car_maker_country_data.cache()\n",
    "\n",
    "    p_car_maker_country_data = car_maker_country_data.toPandas()\n",
    "    car_maker_info_list_countries.append(p_car_maker_country_data)\n",
    "    car_maker_country_data.unpersist()\n",
    "    print 'Done for ' + car_maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_taken_countries = 5\n",
    "\n",
    "#plot\n",
    "fig, axes = plt.subplots(nrows=len(car_makers_name_list), ncols=1, figsize=(15, 20))\n",
    "\n",
    "\n",
    "for j in range(0, len(car_makers_name_list)):\n",
    "    color = 'b'#np.random.rand(3,1)\n",
    "    colors = np.repeat(color, num_taken_countries).tolist()\n",
    "    \n",
    "    country_list_num = car_maker_info_list_countries[j]['COUNT'][:num_taken_countries]\n",
    "    country_list_labels = car_maker_info_list_countries[j]['USER_COUNTRY'][:num_taken_countries]\n",
    "    \n",
    "    for counter in range(0, len(country_list_labels)):\n",
    "        if (country_list_labels[counter] == 'NONE'):\n",
    "            colors[counter] = 'gray'\n",
    "\n",
    "    axes[j].barh(np.arange(num_taken_countries), country_list_num, width, color=colors, align='center')\n",
    "    axes[j].set_xlabel('Num Tweets')\n",
    "    axes[j].set_title('Country Distribution for ' + car_makers_name_list[j])\n",
    "    axes[j].set_yticks(ind)\n",
    "    axes[j].set_yticklabels(country_list_labels.tolist())\n",
    "    \n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots above show the countries with the highest number of tweets about one car maker. You can also calculate the distribution of tweets about all of the car makers for one country and compare countries. Run the following cells to compare these results for the US, UK and Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot for each country\n",
    "us_list = []\n",
    "uk_list = []\n",
    "de_list = []\n",
    "def getListForCountry(x, country):\n",
    "    df=x[x['USER_COUNTRY'] == country]['COUNT']\n",
    "    return [0] if df.empty else [df.tolist()[0]]    \n",
    "\n",
    "for i in range(0, len(car_makers_name_list)):\n",
    "    x = car_maker_info_list_countries[i]\n",
    "    us_list.extend(getListForCountry(x, 'UNITED STATES'))\n",
    "    uk_list.extend(getListForCountry(x, 'UNITED KINGDOM'))\n",
    "    de_list.extend(getListForCountry(x, 'GERMANY'))\n",
    "\n",
    "#plot\n",
    "colors = ['r', 'g', 'b', 'w', 'pink', 'y']\n",
    "us_values = us_list\n",
    "uk_values = uk_list\n",
    "de_values = de_list\n",
    "\n",
    "#plot\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(23, 10))\n",
    "\n",
    "axes[0].pie(us_values,autopct='%1.1f%%', colors=colors, labels=car_makers_name_list)\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_title('Percentage of Tweets from Users in US amoung Car Makers')\n",
    "\n",
    "# Plot\n",
    "axes[1].pie(uk_values,autopct='%1.1f%%', colors=colors, labels=car_makers_name_list)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_title('Percentage of Tweets from Users in UK amoung Car Makers')\n",
    "\n",
    "# Plot\n",
    "axes[2].pie(de_values,autopct='%1.1f%%', colors=colors, labels=car_makers_name_list)\n",
    "axes[2].set_aspect('equal')\n",
    "axes[2].set_title('Percentage of Tweets from Users in GERMANY amoung Car Makers')\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Draw insights about car features\n",
    "\n",
    "In this section, you will analysis the data set to extract insights about car features, for example information about electric cars and self-driving cars.\n",
    "\n",
    "\n",
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCountryDistribution(df):\n",
    "    df_cleaned_tweets_countries = df.groupBy('USER_COUNTRY')\\\n",
    "                .agg(F.count('MESSAGE_BODY').alias('NUM_TWEETS'))\\\n",
    "                .orderBy('NUM_TWEETS', ascending=False)\n",
    "    return df_cleaned_tweets_countries.toPandas()\n",
    "\n",
    "def PlotCountryDistribution(pdf, num_plotted_countries, title):\n",
    "    countries = pdf['USER_COUNTRY'][:num_plotted_countries]\n",
    "    num_tweets = pdf['NUM_TWEETS'][:num_plotted_countries]\n",
    "    y_pos = np.arange(len(countries))\n",
    "    colors = np.repeat('b', num_plotted_countries - 1).tolist()\n",
    "    colors = ['gray'] + colors\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.barh(y_pos, num_tweets, align='center', color=colors)\n",
    "    plt.yticks(y_pos, countries)\n",
    "    plt.xlabel('Number of Tweets')\n",
    "    plt.title(title)\n",
    "    plt.ylim(-1, len(y_pos))\n",
    "    plt.show()\n",
    "\n",
    "#sentiment functions\n",
    "#the dataframe should have the columns Sentiment, MESSAGE_ID\n",
    "def getGeneralSentiment(df):\n",
    "    #get number of tweets with P N U sentiment by grouping the sentiment value\n",
    "    df_grouped_by_sentiment = df\\\n",
    "                            .groupBy('SENTIMENT')\\\n",
    "                            .agg(F.count('MESSAGE_BODY').alias('NUM_TWEETS'))\n",
    "\n",
    "    #move the results to pandas\n",
    "    return df_grouped_by_sentiment.toPandas()\n",
    "\n",
    "\n",
    "#it returns a list which contains a sequence of element. Each element is a list of integer values. Those values are:\n",
    "#total count, male count, female count, positive count, negative count\n",
    "def getCarMaker_Gender_Sentiment_Analysis(df):\n",
    "    final_result_list = []\n",
    "    for car_maker in car_makers_name_list:\n",
    "        result_carMaker_list = []\n",
    "        \n",
    "        df_car_maker = df.filter(df[car_maker] == True)\n",
    "        result_carMaker_list.append(df_car_maker.count())#total count for a car maker        \n",
    "        df_car_maker_male = df_car_maker.filter(df.USER_GENDER == 'male')\n",
    "        result_carMaker_list.append(df_car_maker_male.count())#male count        \n",
    "        df_car_maker_female = df_car_maker.filter(df.USER_GENDER == 'female')\n",
    "        result_carMaker_list.append(df_car_maker_female.count())#female count        \n",
    "        df_car_maker_male.unpersist()\n",
    "        df_car_maker_female.unpersist()        \n",
    "        df_sentiment = df_car_maker.groupBy('SENTIMENT')\\\n",
    "                    .agg(F.count('MESSAGE_BODY').alias('NUM_TWEETS'))\n",
    "        \n",
    "        result_carMaker_list.append(df_sentiment.toPandas())#positive count        \n",
    "        df_sentiment.unpersist()\n",
    "        final_result_list.append(result_carMaker_list)\n",
    "        print 'Done calculation for ' + car_maker\n",
    "    return final_result_list\n",
    "\n",
    "def BarPlot(axes, values, title, ytitle, xlabels):\n",
    "    rects = axes.bar(ind, values, width, color='b', align='center')\n",
    "    axes.set_ylabel(ytitle)\n",
    "    axes.set_title(title)\n",
    "    axes.set_xticks(ind)\n",
    "    axes.set_xticklabels(xlabels)\n",
    "\n",
    "def getPercentag(total, portion):\n",
    "    return 0 if total==0 else (portion*100) / total\n",
    "\n",
    "def getMaleFemaleDistribution(df):\n",
    "    df_grouped_by_gender = df\\\n",
    "            .groupBy('USER_GENDER')\\\n",
    "            .agg(F.count('MESSAGE_BODY').alias('NUM_TWEETS'))    \n",
    "    return df_grouped_by_gender.toPandas()\n",
    "\n",
    "    \n",
    "def Plot_PieChart(pdf, labels_column, values_column, axes, title, plot1_colors):\n",
    "    plot1_labels = map(lambda x:str(x).upper(), pdf[labels_column])\n",
    "    plot1_values = pdf[values_column]\n",
    "    \n",
    "    axes.pie(plot1_values,  labels=plot1_labels, colors=plot1_colors, autopct='%1.1f%%')\n",
    "    axes.set_title(title)\n",
    "    axes.set_aspect('equal')\n",
    "    axes.legend(loc=\"upper right\", labels=plot1_labels)    \n",
    "    \n",
    "#data_list: data to plot has the strucutre: [[list values 1], [list values 2], [list values 3]]\n",
    "def plotHorBarPercentage(axes, data_list, title_string, xtitle, ylabels, color_list, legend_labels):\n",
    "    y_pos = np.arange(len(data_list[0]))\n",
    "    \n",
    "    for i in range(0, len(data_list)):\n",
    "        if (i == 0):\n",
    "            rects = axes.barh(y_pos, data_list[i], align='center', color=color_list[i])\n",
    "            counter = 0\n",
    "            for rect in rects:\n",
    "                axes.text(rect.get_width()/2., rect.get_y() + rect.get_height()/3.,\n",
    "                        '%.1f' % data_list[i][counter] + '%',\n",
    "                        ha='center', va='bottom')\n",
    "                counter += 1\n",
    "        else:\n",
    "            old_value = np.zeros(len(data_list[0])).tolist()\n",
    "            for j in range(0, i):\n",
    "                old_value = [x[0]+x[1] for x in zip(old_value, data_list[j])]\n",
    "            rects = axes.barh(y_pos, data_list[i], align='center', color=color_list[i], left=old_value)\n",
    "            \n",
    "            counter = 0\n",
    "            for rect in rects:\n",
    "                axes.text(rect.get_width()/2. + rect.get_x(), rect.get_y() + rect.get_height()/3.,\n",
    "                        '%.1f' % data_list[i][counter] + '%',\n",
    "                        ha='center', va='bottom')\n",
    "                counter += 1\n",
    "    axes.set_yticks(y_pos)\n",
    "    axes.set_yticklabels(ylabels)\n",
    "    axes.set_xlabel(xtitle)\n",
    "    axes.set_title(title_string)\n",
    "    axes.set_ylim(-1, len(y_pos))\n",
    "    axes.set_xlim(0, 100)\n",
    "    axes.legend(loc=\"upper center\", labels=legend_labels, ncol=len(legend_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw insights about electric cars\n",
    "\n",
    "Some customers are looking to buy an electric vehicle to help save gasoline and protect the environment. For this reason, many car manufacturers have moved to producing electric cars. In this section, you will analyze tweets, which mention electric cars. To find these tweets, you need to search for certain words inside the tweet text such as electric cars, electric motors, etc. The sample uses the search terms in the list called \"electric_vehicle_terms\" to find matches. The list contains terms in four languages, namely in English, French, German, and Spanish.\n",
    "\n",
    "In this section, you will use the the constructed data frame called \"df_tweets_car_maker\". This data frame has a column named ELECTRIC_CARS which indicates whether electric cars were mentioned in a tweet or not. Run the next cell to filter the data according to the value of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_electric_cars = df_tweets_car_maker.filter(df_tweets_car_maker.ELECTRIC_CARS == True)\n",
    "df_electric_cars.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Run the next cell to calculate the number of tweets that speak about electic cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_electric_cars.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculating the country distribution of electric car tweets\n",
    "\n",
    "In this section, you will find the top ten countries with the highest number of tweets about electric cars. \n",
    "<br>\n",
    "Run the next cell to build a pandas DataFrame that contains the data about the country distribution. The computation calls  the helper function \"getCountryDistribution\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_electric_cars_countries = getCountryDistribution(df_electric_cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to plot the country distribution by calling the helper function \"PlotCountryDistribution\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotCountryDistribution(p_electric_cars_countries, 10, 'Tweets Country Distribution for Electric Cars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting sentiment and gender information from tweets about electric cars\n",
    "\n",
    "Run the next cell to collect sentiment information by calling the function \"getGeneralSentiment\". The function returns a pandas DataFrame that contains the data frame regrouped by sentiment values and aggregated by the count function to get the number of tweets for each type of sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_electric_cars_general_sentiment = getGeneralSentiment(df_electric_cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to collect information about the gender distribution in tweets in the data set by calling the function \"getMaleFemaleDistribution\". This function groups the data by the USER_GENDER value and then counts the number of tweets in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_electric_cars_gender_distribution = getMaleFemaleDistribution(df_electric_cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to collect insights about electric cars in tweets related to the 6 car makers and to extract the gender and sentiment information from these tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Calculating the electric car sentiment for each car maker:'\n",
    "electric_cars_carMakers_results = getCarMaker_Gender_Sentiment_Analysis(df_electric_cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the information that you need is in a pandas DataFrame, run the next cell to plot the number of tweets about electric cars across the 6 car manufacturers in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_num_tweets = []\n",
    "for data_car_maker in electric_cars_carMakers_results:\n",
    "    total_num_tweets.append(data_car_maker[0])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 7))\n",
    "BarPlot(axes, total_num_tweets, 'Number of Tweets with Content about Electric Cars', 'Number of Tweets', car_makers_name_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis\n",
    "Run the next cell to firstly plot the general distribution of sentiment values in the electric cars data frame and then to plot the distribution of these values across car makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getSentimentValueFromDataList(data_list, filter):\n",
    "    x = data_list[3]['NUM_TWEETS'][filter].tolist()\n",
    "    if (len(x) > 0):\n",
    "        return x[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "Positive_percentage_list = []\n",
    "Negative_percentage_list = []\n",
    "Ambivalent_percentage_list = []\n",
    "Neutral_percentage_list = []\n",
    "\n",
    "for data_car_maker in electric_cars_carMakers_results:\n",
    "    positive_filter = data_car_maker[3]['SENTIMENT'] == 'POSITIVE'\n",
    "    negative_filter = data_car_maker[3]['SENTIMENT'] == 'NEGATIVE'\n",
    "    neutral_filter = data_car_maker[3]['SENTIMENT'] == 'NEUTRAL'\n",
    "    ambivalent_filter = data_car_maker[3]['SENTIMENT'] == 'AMBIVALENT'\n",
    "    \n",
    "    positive_num_tweets = getSentimentValueFromDataList(data_car_maker, positive_filter)\n",
    "    negative_num_tweets = getSentimentValueFromDataList(data_car_maker, negative_filter)\n",
    "    neutral_num_tweets = getSentimentValueFromDataList(data_car_maker, neutral_filter)\n",
    "    ambivalent_num_tweets = getSentimentValueFromDataList(data_car_maker, ambivalent_filter)\n",
    "    \n",
    "    total_num_tweets_with_sentiment = positive_num_tweets + negative_num_tweets + neutral_num_tweets + ambivalent_num_tweets\n",
    "    \n",
    "    Positive_percentage_list.append(getPercentag(total_num_tweets_with_sentiment, positive_num_tweets))\n",
    "    Negative_percentage_list.append(getPercentag(total_num_tweets_with_sentiment, negative_num_tweets))\n",
    "    Ambivalent_percentage_list.append(getPercentag(total_num_tweets_with_sentiment, ambivalent_num_tweets))\n",
    "    Neutral_percentage_list.append(getPercentag(total_num_tweets_with_sentiment, neutral_num_tweets))\n",
    "    \n",
    "print_list = [Positive_percentage_list, Neutral_percentage_list, Ambivalent_percentage_list, Negative_percentage_list]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "\n",
    "Plot_PieChart(p_electric_cars_general_sentiment, 'SENTIMENT', 'NUM_TWEETS',  axes[0], 'Percentage of Sentiment Values in all Electric Cars Tweets',\\\n",
    "                     ['Violet', 'red', 'gray', 'yellow', 'green'])\n",
    "plotHorBarPercentage(axes[1], print_list, 'Sentiment in Electric Cars Tweets According to Car Makers', 'Percentage Value', car_makers_name_list, ['b', 'gray', 'green', 'red'], ['POSITIVE', 'NEUTRAL', 'AMBIVALENT', 'NEGATIVE'])\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender distribution\n",
    "\n",
    "The next cell plots the distribution of gender in the electric cars data frame and then plots the distribution of these values across car makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "male_percentage_list = []\n",
    "female_percentage_list = []\n",
    "rest_percentage_list = []\n",
    "for data_car_maker in electric_cars_carMakers_results:\n",
    "    male_percentage_list.append(getPercentag(data_car_maker[0], data_car_maker[1]))\n",
    "    female_percentage_list.append(getPercentag(data_car_maker[0], data_car_maker[2]))\n",
    "    rest_percentage_list.append(getPercentag(data_car_maker[0], data_car_maker[0] - (data_car_maker[1] + data_car_maker[2])))\n",
    "    \n",
    "print_list = [male_percentage_list, rest_percentage_list, female_percentage_list]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "Plot_PieChart(p_electric_cars_gender_distribution, 'USER_GENDER', 'NUM_TWEETS', axes[0], 'Percentage of Sentiment Values in all Electric Cars Tweets',\\\n",
    "                     ['Violet', 'red', 'gray', 'yellow', 'green'])\n",
    "plotHorBarPercentage(axes[1], print_list, 'Male Female Distribution who Mention Electric Cars', 'Percentage Value', car_makers_name_list, ['b', 'gray', 'red'], ['MALE', 'UNKNOWN', 'FEMALE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-driving cars\n",
    "\n",
    "In this section, you will perform an analysis to extract insights about self-driving cars from tweets in the data set. To find these tweets, you need to search for certain words inside the tweet text such as self-driving cars, autodrive cars, robot cars, etc. The sample uses the search terms in the list called \"auto_driver_terms\" to find matches. The list contains terms in four languages, namely in English, French, German, and Spanish.\n",
    "\n",
    "\n",
    "In this section, you will use the constructed data frame called \"df_tweets_car_maker\". This data frame has a column named AUTO_DRIVE which indicates whether self-driving cars were mentioned in a tweet or not. Run the next cell to filter the data according to the value of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_autodrive = df_tweets_car_maker.filter(df_tweets_car_maker.AUTO_DRIVE == True)\n",
    "df_autodrive.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to calculate the number of tweets that mention self-driving cars in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_autodrive.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country distribution\n",
    "\n",
    "In this section, you will find the top ten countries with the highest number of tweets about self-driving cars. \n",
    "<br>\n",
    "Run the next cell to build a pandas DataFrame that contains the data about the country distribution for tweets about self-driving cars. The computation calls  the helper function \"getCountryDistribution\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_autodrive_countries = getCountryDistribution(df_autodrive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to plot the country distribution by calling the helper function \"PlotCountryDistribution\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotCountryDistribution(p_autodrive_countries, 10, 'Tweets Country Distribution based on the User Profile - AutoDrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting sentiment and gender information from tweets about self-driving cars\n",
    "\n",
    "Run the next cell to collect sentiment information by calling the function \"getGeneralSentiment\". The function returns a pandas DataFrame that contains the data frame regrouped by sentiment values and aggregated by the count function to get the number of tweets for each type of sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_autodrive_general_sentiment = getGeneralSentiment(df_autodrive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to collect information about the gender distribution in tweets about self-driving cars by calling the function \"getMaleFemaleDistribution\". This function groups the data by the USER_GENDER value and then counts the number of tweets in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_autodrive_gender_distribution = getMaleFemaleDistribution(df_autodrive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to collect insights about self-driving cars in tweets related to the 6 car makers and to extract the gender and sentiment information from these tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Calculating the autodrive car sentiment for each car maker:'\n",
    "auto_drive_carMakers_results = getCarMaker_Gender_Sentiment_Analysis(df_autodrive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the information that you need is in a pandas DataFrame, run the next cell to plot the number of tweets about self-driving cars across the 6 car manufacturers in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_num_tweets = []\n",
    "for data_car_maker in auto_drive_carMakers_results:\n",
    "    total_num_tweets.append(data_car_maker[0])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 7))\n",
    "BarPlot(axes, total_num_tweets, 'Number of Tweets with Content about AutoDrive Cars', 'Number of Tweets', car_makers_name_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis\n",
    "Run the next cell to firstly plot the general distribution of sentiment values in the autodrive cars data frame and then to plot the distribution of these values across car makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getSentimentValueFromDataList(data_list, filter):\n",
    "    x = data_list[3]['NUM_TWEETS'][filter].tolist()\n",
    "    if (len(x) > 0):\n",
    "        return x[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "Positive_percentage_list = []\n",
    "Negative_percentage_list = []\n",
    "Ambivalent_percentage_list = []\n",
    "Neutral_percentage_list = []\n",
    "\n",
    "for data_car_maker in auto_drive_carMakers_results:\n",
    "    positive_filter = data_car_maker[3]['SENTIMENT'] == 'POSITIVE'\n",
    "    negative_filter = data_car_maker[3]['SENTIMENT'] == 'NEGATIVE'\n",
    "    neutral_filter = data_car_maker[3]['SENTIMENT'] == 'NEUTRAL'\n",
    "    ambivalent_filter = data_car_maker[3]['SENTIMENT'] == 'AMBIVALENT'\n",
    "    \n",
    "    positive_num_tweets = getSentimentValueFromDataList(data_car_maker, positive_filter)\n",
    "    negative_num_tweets = getSentimentValueFromDataList(data_car_maker, negative_filter)\n",
    "    neutral_num_tweets = getSentimentValueFromDataList(data_car_maker, neutral_filter)\n",
    "    ambivalent_num_tweets = getSentimentValueFromDataList(data_car_maker, ambivalent_filter)\n",
    "    \n",
    "    total_num_tweets_with_sentiment = positive_num_tweets + negative_num_tweets + neutral_num_tweets + ambivalent_num_tweets\n",
    "    \n",
    "    Positive_percentage_list.append(getPercentag(total_num_tweets_with_sentiment, positive_num_tweets))\n",
    "    Negative_percentage_list.append(getPercentag(total_num_tweets_with_sentiment, negative_num_tweets))\n",
    "    Ambivalent_percentage_list.append(getPercentag(total_num_tweets_with_sentiment, ambivalent_num_tweets))\n",
    "    Neutral_percentage_list.append(getPercentag(total_num_tweets_with_sentiment, neutral_num_tweets))\n",
    "    \n",
    "    \n",
    "\n",
    "print_list = [Positive_percentage_list, Neutral_percentage_list, Ambivalent_percentage_list, Negative_percentage_list]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "\n",
    "Plot_PieChart(p_autodrive_general_sentiment, 'SENTIMENT', 'NUM_TWEETS',  axes[0], 'Percentage of Sentiment Values in all AutoDrive Tweets',\\\n",
    "                     ['Violet', 'red', 'gray', 'yellow', 'green'])\n",
    "\n",
    "plotHorBarPercentage(axes[1], print_list, 'Sentiment in AutoDrive Tweets According to Car Makers', 'Percentage Value', car_makers_name_list, ['b', 'gray', 'green', 'red'], ['POSITIVE', 'NEUTRAL', 'AMBIVALENT', 'NEGATIVE'])\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender distribution\n",
    "\n",
    "The next cell plots the distribution of gender in the autodrive cars data frame and then plots the distribution of these values across car makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "male_percentage_list = []\n",
    "female_percentage_list = []\n",
    "rest_percentage_list = []\n",
    "for data_car_maker in auto_drive_carMakers_results:\n",
    "    male_percentage_list.append(getPercentag(data_car_maker[0], data_car_maker[1]))\n",
    "    female_percentage_list.append(getPercentag(data_car_maker[0], data_car_maker[2]))\n",
    "    rest_percentage_list.append(getPercentag(data_car_maker[0], data_car_maker[0] - (data_car_maker[1] + data_car_maker[2])))\n",
    "    \n",
    "print_list = [male_percentage_list, rest_percentage_list, female_percentage_list]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "Plot_PieChart(p_autodrive_gender_distribution, 'USER_GENDER', 'NUM_TWEETS', axes[0], 'Percentage of Sentiment Values in all AutoDrive Tweets',\\\n",
    "                     ['Violet', 'red', 'gray', 'yellow', 'green'])\n",
    "plotHorBarPercentage(axes[1], print_list, 'Male Female Distribution who Mention AutoDrive Cars', 'Percentage Value', car_makers_name_list, ['b', 'gray', 'red'], ['MALE', 'UNKNOWN', 'FEMALE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 10. Summary\n",
    "In this Notebook you learned how to use notebooks to analyze Twitter data and extract interesting insights from tweets. You learned how to easily perform complex computations on a large amount of data in a notebooks by using SparkContext, which enables you to start tasks on the Spark cluster. In addition, you learned how to integrate data from dashDB using the Spark connector and how to use Spark and pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
